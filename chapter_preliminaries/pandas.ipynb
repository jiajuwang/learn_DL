{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3766a2be",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# Data Preprocessing\n",
    ":label:`sec_pandas`\n",
    "\n",
    "So far, we have been working with synthetic data\n",
    "that arrived in ready-made tensors.\n",
    "However, to apply deep learning in the wild\n",
    "we must extract messy data \n",
    "stored in arbitrary formats,\n",
    "and preprocess it to suit our needs.\n",
    "Fortunately, the *pandas* [library](https://pandas.pydata.org/) \n",
    "can do much of the heavy lifting.\n",
    "This section, while no substitute \n",
    "for a proper *pandas* [tutorial](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html),\n",
    "will give you a crash course\n",
    "on some of the most common routines.\n",
    "\n",
    "## Reading the Dataset\n",
    "\n",
    "Comma-separated values (CSV) files are ubiquitous \n",
    "for the storing of tabular (spreadsheet-like) data.\n",
    "In them, each line corresponds to one record\n",
    "and consists of several (comma-separated) fields, e.g.,\n",
    "\"Albert Einstein,March 14 1879,Ulm,Federal polytechnic school,field of gravitational physics\".\n",
    "To demonstrate how to load CSV files with `pandas`, \n",
    "we (**create a CSV file below**) `../data/house_tiny.csv`. \n",
    "This file represents a dataset of homes,\n",
    "where each row corresponds to a distinct home\n",
    "and the columns correspond to the number of rooms (`NumRooms`),\n",
    "the roof type (`RoofType`), and the price (`Price`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bea3f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:20.494944Z",
     "iopub.status.busy": "2023-08-18T19:31:20.494290Z",
     "iopub.status.idle": "2023-08-18T19:31:20.505610Z",
     "shell.execute_reply": "2023-08-18T19:31:20.504677Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('''NumRooms,RoofType,Price\n",
    "NA,NA,127500\n",
    "2,NA,106000\n",
    "4,Slate,178100\n",
    "NA,NA,140000''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73772a6",
   "metadata": {
    "origin_pos": 3
   },
   "source": [
    "Now let's import `pandas` and load the dataset with `read_csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ae201e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:20.510380Z",
     "iopub.status.busy": "2023-08-18T19:31:20.509849Z",
     "iopub.status.idle": "2023-08-18T19:31:21.105668Z",
     "shell.execute_reply": "2023-08-18T19:31:21.104596Z"
    },
    "origin_pos": 4,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms RoofType   Price\n",
      "0       NaN      NaN  127500\n",
      "1       2.0      NaN  106000\n",
      "2       4.0    Slate  178100\n",
      "3       NaN      NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb4eec",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "In supervised learning, we train models\n",
    "to predict a designated *target* value,\n",
    "given some set of *input* values. \n",
    "Our first step in processing the dataset\n",
    "is to separate out columns corresponding\n",
    "to input versus target values. \n",
    "We can select columns either by name or\n",
    "via integer-location based indexing (`iloc`).\n",
    "\n",
    "You might have noticed that `pandas` replaced\n",
    "all CSV entries with value `NA`\n",
    "with a special `NaN` (*not a number*) value. \n",
    "This can also happen whenever an entry is empty,\n",
    "e.g., \"3,,,270000\".\n",
    "These are called *missing values* \n",
    "and they are the \"bed bugs\" of data science,\n",
    "a persistent menace that you will confront\n",
    "throughout your career. \n",
    "Depending upon the context, \n",
    "missing values might be handled\n",
    "either via *imputation* or *deletion*.\n",
    "Imputation replaces missing values \n",
    "with estimates of their values\n",
    "while deletion simply discards \n",
    "either those rows or those columns\n",
    "that contain missing values. \n",
    "\n",
    "Here are some common imputation heuristics.\n",
    "[**For categorical input fields, \n",
    "we can treat `NaN` as a category.**]\n",
    "Since the `RoofType` column takes values `Slate` and `NaN`,\n",
    "`pandas` can convert this column \n",
    "into two columns `RoofType_Slate` and `RoofType_nan`.\n",
    "A row whose roof type is `Slate` will set values \n",
    "of `RoofType_Slate` and `RoofType_nan` to 1 and 0, respectively.\n",
    "The converse holds for a row with a missing `RoofType` value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f92e80b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:21.109879Z",
     "iopub.status.busy": "2023-08-18T19:31:21.109243Z",
     "iopub.status.idle": "2023-08-18T19:31:21.120081Z",
     "shell.execute_reply": "2023-08-18T19:31:21.119081Z"
    },
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  RoofType_Slate  RoofType_nan\n",
      "0       NaN           False          True\n",
      "1       2.0           False          True\n",
      "2       4.0            True         False\n",
      "3       NaN           False          True\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea48715",
   "metadata": {
    "origin_pos": 7
   },
   "source": [
    "For missing numerical values, \n",
    "one common heuristic is to \n",
    "[**replace the `NaN` entries with \n",
    "the mean value of the corresponding column**].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e8e900",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:21.123941Z",
     "iopub.status.busy": "2023-08-18T19:31:21.123273Z",
     "iopub.status.idle": "2023-08-18T19:31:21.132513Z",
     "shell.execute_reply": "2023-08-18T19:31:21.131522Z"
    },
    "origin_pos": 8,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  RoofType_Slate  RoofType_nan\n",
      "0       3.0           False          True\n",
      "1       2.0           False          True\n",
      "2       4.0            True         False\n",
      "3       3.0           False          True\n"
     ]
    }
   ],
   "source": [
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d535cf",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "## Conversion to the Tensor Format\n",
    "\n",
    "Now that [**all the entries in `inputs` and `targets` are numerical,\n",
    "we can load them into a tensor**] (recall :numref:`sec_ndarray`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d211233b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T19:31:21.137043Z",
     "iopub.status.busy": "2023-08-18T19:31:21.136126Z",
     "iopub.status.idle": "2023-08-18T19:31:23.159251Z",
     "shell.execute_reply": "2023-08-18T19:31:23.158224Z"
    },
    "origin_pos": 11,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 0., 1.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 1., 0.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500., 106000., 178100., 140000.], dtype=torch.float64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor(inputs.to_numpy(dtype=float))\n",
    "y = torch.tensor(targets.to_numpy(dtype=float))\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3027b6",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "## Discussion\n",
    "\n",
    "You now know how to partition data columns, \n",
    "impute missing variables, \n",
    "and load `pandas` data into tensors. \n",
    "In :numref:`sec_kaggle_house`, you will\n",
    "pick up some more data processing skills. \n",
    "While this crash course kept things simple,\n",
    "data processing can get hairy.\n",
    "For example, rather than arriving in a single CSV file,\n",
    "our dataset might be spread across multiple files\n",
    "extracted from a relational database.\n",
    "For instance, in an e-commerce application,\n",
    "customer addresses might live in one table\n",
    "and purchase data in another.\n",
    "Moreover, practitioners face myriad data types\n",
    "beyond categorical and numeric, for example,\n",
    "text strings, images,\n",
    "audio data, and point clouds. \n",
    "Oftentimes, advanced tools and efficient algorithms \n",
    "are required in order to prevent data processing from becoming\n",
    "the biggest bottleneck in the machine learning pipeline. \n",
    "These problems will arise when we get to \n",
    "computer vision and natural language processing. \n",
    "Finally, we must pay attention to data quality.\n",
    "Real-world datasets are often plagued \n",
    "by outliers, faulty measurements from sensors, and recording errors, \n",
    "which must be addressed before \n",
    "feeding the data into any model. \n",
    "Data visualization tools such as [seaborn](https://seaborn.pydata.org/), \n",
    "[Bokeh](https://docs.bokeh.org/), or [matplotlib](https://matplotlib.org/)\n",
    "can help you to manually inspect the data \n",
    "and develop intuitions about \n",
    "the type of problems you may need to address.\n",
    "\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Try loading datasets, e.g., Abalone from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.php) and inspect their properties. What fraction of them has missing values? What fraction of the variables is numerical, categorical, or text?\n",
    "1. Try indexing and selecting data columns by name rather than by column number. The pandas documentation on [indexing](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html) has further details on how to do this.\n",
    "1. How large a dataset do you think you could load this way? What might be the limitations? Hint: consider the time to read the data, representation, processing, and memory footprint. Try this out on your laptop. What happens if you try it out on a server? \n",
    "1. How would you deal with data that has a very large number of categories? What if the category labels are all unique? Should you include the latter?\n",
    "1. What alternatives to pandas can you think of? How about [loading NumPy tensors from a file](https://numpy.org/doc/stable/reference/generated/numpy.load.html)? Check out [Pillow](https://python-pillow.org/), the Python Imaging Library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634223ee",
   "metadata": {
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2add63fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\wangj\\miniconda3\\envs\\d21_gpu\\lib\\site-packages (from ucimlrepo) (2.2.3)\n",
      "Collecting certifi>=2020.12.5 (from ucimlrepo)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\wangj\\miniconda3\\envs\\d21_gpu\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wangj\\miniconda3\\envs\\d21_gpu\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wangj\\miniconda3\\envs\\d21_gpu\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\wangj\\miniconda3\\envs\\d21_gpu\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wangj\\miniconda3\\envs\\d21_gpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
      "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: certifi, ucimlrepo\n",
      "\n",
      "   ---------------------------------------- 2/2 [ucimlrepo]\n",
      "\n",
      "Successfully installed certifi-2025.4.26 ucimlrepo-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57985663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'ID': 191, 'type': 'NATIVE', 'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'venue': 'Significance, 2021', 'year': 2021, 'journal': 'Significance, 2021', 'DOI': '1740-9713.01589', 'URL': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
      "           name     role         type demographic  \\\n",
      "0  sepal length  Feature   Continuous        None   \n",
      "1   sepal width  Feature   Continuous        None   \n",
      "2  petal length  Feature   Continuous        None   \n",
      "3   petal width  Feature   Continuous        None   \n",
      "4         class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                               None    cm             no  \n",
      "1                                               None    cm             no  \n",
      "2                                               None    cm             no  \n",
      "3                                               None    cm             no  \n",
      "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = iris.data.features \n",
    "y = iris.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(iris.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(iris.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e62280c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(iris.metadata.num_instances)\n",
    "print(iris.metadata.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d20ae00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width\n",
      "0             5.1          3.5           1.4          0.2\n",
      "1             4.9          3.0           1.4          0.2\n",
      "2             4.7          3.2           1.3          0.2\n",
      "3             4.6          3.1           1.5          0.2\n",
      "4             5.0          3.6           1.4          0.2\n",
      "..            ...          ...           ...          ...\n",
      "145           6.7          3.0           5.2          2.3\n",
      "146           6.3          2.5           5.0          1.9\n",
      "147           6.5          3.0           5.2          2.0\n",
      "148           6.2          3.4           5.4          2.3\n",
      "149           5.9          3.0           5.1          1.8\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(X, dummy_na=True)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e99ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      5.1\n",
      "1      4.9\n",
      "2      4.7\n",
      "3      4.6\n",
      "4      5.0\n",
      "      ... \n",
      "145    6.7\n",
      "146    6.3\n",
      "147    6.5\n",
      "148    6.2\n",
      "149    5.9\n",
      "Name: sepal length, Length: 150, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X['sepal length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ba8d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data.features\n",
    "Y = iris.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbc7a513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              class\n",
      "0       Iris-setosa\n",
      "1       Iris-setosa\n",
      "2       Iris-setosa\n",
      "3       Iris-setosa\n",
      "4       Iris-setosa\n",
      "..              ...\n",
      "145  Iris-virginica\n",
      "146  Iris-virginica\n",
      "147  Iris-virginica\n",
      "148  Iris-virginica\n",
      "149  Iris-virginica\n",
      "\n",
      "[150 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09de97e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica', 'Iris-virginica']\n",
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "145    2\n",
      "146    2\n",
      "147    2\n",
      "148    2\n",
      "149    2\n",
      "Name: class, Length: 150, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert Y to categorical codes\n",
    "dict = {}\n",
    "index = 0\n",
    "Y_series = Y.squeeze()\n",
    "print(Y_series.tolist())\n",
    "for i in Y_series.tolist():\n",
    "    if i not in dict:\n",
    "        dict[i] = index\n",
    "        index += 1\n",
    "Y = Y_series.map(dict)\n",
    "print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fbb17f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "        2., 2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
      "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
      "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
      "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
      "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
      "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
      "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.1000],\n",
      "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
      "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
      "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
      "        [5.4000, 3.9000, 1.3000, 0.4000],\n",
      "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
      "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
      "        [5.1000, 3.8000, 1.5000, 0.3000],\n",
      "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
      "        [5.1000, 3.7000, 1.5000, 0.4000],\n",
      "        [4.6000, 3.6000, 1.0000, 0.2000],\n",
      "        [5.1000, 3.3000, 1.7000, 0.5000],\n",
      "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
      "        [5.0000, 3.0000, 1.6000, 0.2000],\n",
      "        [5.0000, 3.4000, 1.6000, 0.4000],\n",
      "        [5.2000, 3.5000, 1.5000, 0.2000],\n",
      "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
      "        [4.7000, 3.2000, 1.6000, 0.2000],\n",
      "        [4.8000, 3.1000, 1.6000, 0.2000],\n",
      "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
      "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
      "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [5.0000, 3.2000, 1.2000, 0.2000],\n",
      "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
      "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
      "        [4.4000, 3.0000, 1.3000, 0.2000],\n",
      "        [5.1000, 3.4000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
      "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
      "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
      "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
      "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
      "        [4.8000, 3.0000, 1.4000, 0.3000],\n",
      "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
      "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
      "        [5.3000, 3.7000, 1.5000, 0.2000],\n",
      "        [5.0000, 3.3000, 1.4000, 0.2000],\n",
      "        [7.0000, 3.2000, 4.7000, 1.4000],\n",
      "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
      "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
      "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
      "        [6.5000, 2.8000, 4.6000, 1.5000],\n",
      "        [5.7000, 2.8000, 4.5000, 1.3000],\n",
      "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
      "        [4.9000, 2.4000, 3.3000, 1.0000],\n",
      "        [6.6000, 2.9000, 4.6000, 1.3000],\n",
      "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
      "        [5.0000, 2.0000, 3.5000, 1.0000],\n",
      "        [5.9000, 3.0000, 4.2000, 1.5000],\n",
      "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
      "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
      "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
      "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
      "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
      "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
      "        [6.2000, 2.2000, 4.5000, 1.5000],\n",
      "        [5.6000, 2.5000, 3.9000, 1.1000],\n",
      "        [5.9000, 3.2000, 4.8000, 1.8000],\n",
      "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
      "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
      "        [6.1000, 2.8000, 4.7000, 1.2000],\n",
      "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
      "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
      "        [6.8000, 2.8000, 4.8000, 1.4000],\n",
      "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
      "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
      "        [5.7000, 2.6000, 3.5000, 1.0000],\n",
      "        [5.5000, 2.4000, 3.8000, 1.1000],\n",
      "        [5.5000, 2.4000, 3.7000, 1.0000],\n",
      "        [5.8000, 2.7000, 3.9000, 1.2000],\n",
      "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
      "        [5.4000, 3.0000, 4.5000, 1.5000],\n",
      "        [6.0000, 3.4000, 4.5000, 1.6000],\n",
      "        [6.7000, 3.1000, 4.7000, 1.5000],\n",
      "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
      "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
      "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
      "        [5.5000, 2.6000, 4.4000, 1.2000],\n",
      "        [6.1000, 3.0000, 4.6000, 1.4000],\n",
      "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
      "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
      "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
      "        [5.7000, 3.0000, 4.2000, 1.2000],\n",
      "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
      "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
      "        [5.1000, 2.5000, 3.0000, 1.1000],\n",
      "        [5.7000, 2.8000, 4.1000, 1.3000],\n",
      "        [6.3000, 3.3000, 6.0000, 2.5000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [7.1000, 3.0000, 5.9000, 2.1000],\n",
      "        [6.3000, 2.9000, 5.6000, 1.8000],\n",
      "        [6.5000, 3.0000, 5.8000, 2.2000],\n",
      "        [7.6000, 3.0000, 6.6000, 2.1000],\n",
      "        [4.9000, 2.5000, 4.5000, 1.7000],\n",
      "        [7.3000, 2.9000, 6.3000, 1.8000],\n",
      "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
      "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
      "        [6.5000, 3.2000, 5.1000, 2.0000],\n",
      "        [6.4000, 2.7000, 5.3000, 1.9000],\n",
      "        [6.8000, 3.0000, 5.5000, 2.1000],\n",
      "        [5.7000, 2.5000, 5.0000, 2.0000],\n",
      "        [5.8000, 2.8000, 5.1000, 2.4000],\n",
      "        [6.4000, 3.2000, 5.3000, 2.3000],\n",
      "        [6.5000, 3.0000, 5.5000, 1.8000],\n",
      "        [7.7000, 3.8000, 6.7000, 2.2000],\n",
      "        [7.7000, 2.6000, 6.9000, 2.3000],\n",
      "        [6.0000, 2.2000, 5.0000, 1.5000],\n",
      "        [6.9000, 3.2000, 5.7000, 2.3000],\n",
      "        [5.6000, 2.8000, 4.9000, 2.0000],\n",
      "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
      "        [6.3000, 2.7000, 4.9000, 1.8000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
      "        [7.2000, 3.2000, 6.0000, 1.8000],\n",
      "        [6.2000, 2.8000, 4.8000, 1.8000],\n",
      "        [6.1000, 3.0000, 4.9000, 1.8000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.1000],\n",
      "        [7.2000, 3.0000, 5.8000, 1.6000],\n",
      "        [7.4000, 2.8000, 6.1000, 1.9000],\n",
      "        [7.9000, 3.8000, 6.4000, 2.0000],\n",
      "        [6.4000, 2.8000, 5.6000, 2.2000],\n",
      "        [6.3000, 2.8000, 5.1000, 1.5000],\n",
      "        [6.1000, 2.6000, 5.6000, 1.4000],\n",
      "        [7.7000, 3.0000, 6.1000, 2.3000],\n",
      "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
      "        [6.4000, 3.1000, 5.5000, 1.8000],\n",
      "        [6.0000, 3.0000, 4.8000, 1.8000],\n",
      "        [6.9000, 3.1000, 5.4000, 2.1000],\n",
      "        [6.7000, 3.1000, 5.6000, 2.4000],\n",
      "        [6.9000, 3.1000, 5.1000, 2.3000],\n",
      "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
      "        [6.8000, 3.2000, 5.9000, 2.3000],\n",
      "        [6.7000, 3.3000, 5.7000, 2.5000],\n",
      "        [6.7000, 3.0000, 5.2000, 2.3000],\n",
      "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
      "        [6.5000, 3.0000, 5.2000, 2.0000],\n",
      "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
      "        [5.9000, 3.0000, 5.1000, 1.8000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y_tensor = torch.tensor(Y.to_numpy(dtype=float))\n",
    "print(y_tensor)\n",
    "X_tensor = torch.tensor(X.to_numpy(dtype=float))\n",
    "print(X_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d21_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "required_libs": []
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
